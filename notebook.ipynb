{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Tree Optimization Project\n",
    "\n",
    "## Course Information\n",
    "\n",
    "This project is part of the Master's Degree in Computer Engineering course, specifically for the \"Optimization\" class taught by Professor Francesca Maggioni.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "The task for this course is to **implement one of the classification trees** presented in the paper by Bertsimas and Dunn and apply it to a real-life dataset discussed in the article.\n",
    "\n",
    "### Paper Reference\n",
    "\n",
    "- **Title**: Optimal Classification Trees\n",
    "- **Authors**: Dimitris Bertsimas and Julia Dunn\n",
    "- **Journal**: Machine Learning\n",
    "- **Volume**: 106\n",
    "- **Pages**: 1039–1082\n",
    "- **Year**: 2017\n",
    "- **DOI**: [10.1007/s10994-017-5633-9](https://doi.org/10.1007/s10994-017-5633-9)\n",
    "\n",
    "### Objective\n",
    "\n",
    "The objective of this project is to:\n",
    "\n",
    "1. Implement a classification tree based on the methodology described in the paper.\n",
    "2. Apply the implemented model to a real-world dataset to evaluate its performance and effectiveness.\n",
    "\n",
    "### Overview of the Implementation\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "1. **Load and Prepare Data**: Import the dataset and preprocess it for use in the classification tree model.\n",
    "2. **Standardize the Data**: Ensure that the data is scaled appropriately for the model.\n",
    "3. **Split the Dataset**: Divide the data into training and test sets for model evaluation.\n",
    "4. **Configure the Model**: Set up the parameters and constants for the classification tree model.\n",
    "5. **Train and Tune the Model**: Train the model using the training data and fine-tune it for optimal performance.\n",
    "6. **Compare Different Solvers**: Evaluate the performance of various solvers in solving the classification tree model.\n",
    "7. **Evaluate and Report Results**: Assess the model’s performance on both training and test data and present the results.\n",
    "\n",
    "By following these steps, we aim to understand the application of optimization techniques in classification problems and gain insights into the performance of classification trees on real-world data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "\n",
    "To ensure a smooth development process, it is recommended to use a virtual environment. This helps manage dependencies and avoid conflicts. You can choose between `venv` or `conda` for creating the virtual environment.\n",
    "\n",
    "### Using `venv`\n",
    "\n",
    "1. **Create a virtual environment**:\n",
    "    ```bash\n",
    "    python -m venv myenv\n",
    "    ```\n",
    "\n",
    "2. **Activate the virtual environment**:\n",
    "    - On Windows:\n",
    "      ```bash\n",
    "      myenv\\Scripts\\activate\n",
    "      ```\n",
    "    - On macOS and Linux:\n",
    "      ```bash\n",
    "      source myenv/bin/activate\n",
    "      ```\n",
    "\n",
    "3. **Install dependencies**:\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "### Using `conda`\n",
    "\n",
    "1. **Create a new conda environment** with Python 3.12:\n",
    "    ```bash\n",
    "    conda create -n myenv python=3.12\n",
    "    ```\n",
    "\n",
    "2. **Activate the conda environment**:\n",
    "    ```bash\n",
    "    conda activate myenv\n",
    "    ```\n",
    "\n",
    "3. **Install dependencies**:\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "### Python Version\n",
    "\n",
    "Ensure you are using **Python 3.12** for compatibility with the dependencies and the project code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting constants and model parameters\n",
    "\n",
    "In this section, we define key constants and parameters that will be used throughout the model training and evaluation process.\n",
    "These include the random seed for reproducibility, dataset split ratios, and model-specific parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "SEED = 26\n",
    "\n",
    "# Split parameters\n",
    "TRAIN_SIZE = 0.1\n",
    "TEST_SIZE = 1 - TRAIN_SIZE\n",
    "\n",
    "# Model parameters\n",
    "ALPHA = 5 # complexity\n",
    "MIN_SAMPLES_PER_LEAF = 2 # minimum number of samples per leaf\n",
    "MAX_DEPTH = 3 # max depth of the tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing required packages and importing libraries\n",
    "\n",
    "In this section, we install the necessary packages and import the required libraries for our project, this includes specific versions for reproducibility and compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# When pyomo will support numpy 2.0, we will update the version\n",
    "%pip install numpy==1.26.4 \\\n",
    "    scipy \\\n",
    "    matplotlib \\\n",
    "    scikit-learn \\\n",
    "    ucimlrepo \\\n",
    "    pyomo==6.7.3 --quiet\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pyomo.environ as pyo\n",
    "import importlib\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src import MIOTree\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions\n",
    "\n",
    "This section defines two utility functions: one for standardizing data and another for printing the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data points (mean 0 and std dev 1).\"\"\"\n",
    "    x = x - np.mean(x)\n",
    "    x = x / np.std(x)\n",
    "    return x\n",
    "\n",
    "def print_confusion_matrix(classes, confusion_matrix):\n",
    "    \"\"\"Print the confusion matrix.\"\"\"\n",
    "    print('Confusion Matrix:')\n",
    "    print ('Act/Pred\\t(0)\\t(1)')\n",
    "    for index in range(len(confusion_matrix)):\n",
    "        print(f'({classes[index]})\\t\\t', end='')\n",
    "        for val in confusion_matrix[index]:\n",
    "            print(val, end='\\t')\n",
    "        print()\n",
    "\n",
    "def extract_leaf_predictions(model):\n",
    "    classes = np.unique(model.y_train)\n",
    "\n",
    "    num_leaf_nodes = len(model.pyomo_model.leaf_nodes)\n",
    "    leaf_predictions = [None] * num_leaf_nodes\n",
    "\n",
    "    class_index_to_label = {i: classes[i] for i in model.pyomo_model.classes_indices}\n",
    "\n",
    "\n",
    "    for i in model.pyomo_model.classes_indices:\n",
    "        for j in model.pyomo_model.leaf_nodes:\n",
    "            if model.pyomo_model.c[i, j].value == 1:\n",
    "                leaf_index = j - num_leaf_nodes\n",
    "                if 0 <= leaf_index < num_leaf_nodes:\n",
    "                    leaf_predictions[leaf_index] = class_index_to_label[i]\n",
    "\n",
    "    return leaf_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching and processing the dataset\n",
    "\n",
    "In this section, we fetch a dataset from the UCI Machine Learning Repository, process it into NumPy arrays, and print out metadata and variable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 94, 'name': 'Spambase', 'repository_url': 'https://archive.ics.uci.edu/dataset/94/spambase', 'data_url': 'https://archive.ics.uci.edu/static/public/94/data.csv', 'abstract': 'Classifying Email as Spam or Non-Spam', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 4601, 'num_features': 57, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1999, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C53G6X', 'creators': ['Mark Hopkins', 'Erik Reeber', 'George Forman', 'Jaap Suermondt'], 'intro_paper': None, 'additional_info': {'summary': 'The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\\n\\nThe classification task for this dataset is to determine whether a given email is spam or not.\\n\\t\\nOur collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word \\'george\\' and the area code \\'650\\' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\\n\\nFor background on spam: Cranor, Lorrie F., LaMacchia, Brian A.  Spam!, Communications of the ACM, 41(8):74-83, 1998.\\n\\nTypical performance is around ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter. See also Hewlett-Packard Internal-only Technical Report. External version forthcoming. ', 'purpose': None, 'funded_by': None, 'instances_represent': 'Emails', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The last column of \\'spambase.data\\' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:\\r\\n\\r\\n48 continuous real [0,100] attributes of type word_freq_WORD \\r\\n= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\\r\\n\\r\\n6 continuous real [0,100] attributes of type char_freq_CHAR] \\r\\n= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\r\\n\\r\\n1 continuous real [1,...] attribute of type capital_run_length_average \\r\\n= average length of uninterrupted sequences of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_longest \\r\\n= length of longest uninterrupted sequence of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_total \\r\\n= sum of length of uninterrupted sequences of capital letters \\r\\n= total number of capital letters in the e-mail\\r\\n\\r\\n1 nominal {0,1} class attribute of type spam\\r\\n= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \\r\\n', 'citation': None}}\n",
      "                          name     role        type demographic  \\\n",
      "0               word_freq_make  Feature  Continuous        None   \n",
      "1            word_freq_address  Feature  Continuous        None   \n",
      "2                word_freq_all  Feature  Continuous        None   \n",
      "3                 word_freq_3d  Feature  Continuous        None   \n",
      "4                word_freq_our  Feature  Continuous        None   \n",
      "5               word_freq_over  Feature  Continuous        None   \n",
      "6             word_freq_remove  Feature  Continuous        None   \n",
      "7           word_freq_internet  Feature  Continuous        None   \n",
      "8              word_freq_order  Feature  Continuous        None   \n",
      "9               word_freq_mail  Feature  Continuous        None   \n",
      "10           word_freq_receive  Feature  Continuous        None   \n",
      "11              word_freq_will  Feature  Continuous        None   \n",
      "12            word_freq_people  Feature  Continuous        None   \n",
      "13            word_freq_report  Feature  Continuous        None   \n",
      "14         word_freq_addresses  Feature  Continuous        None   \n",
      "15              word_freq_free  Feature  Continuous        None   \n",
      "16          word_freq_business  Feature  Continuous        None   \n",
      "17             word_freq_email  Feature  Continuous        None   \n",
      "18               word_freq_you  Feature  Continuous        None   \n",
      "19            word_freq_credit  Feature  Continuous        None   \n",
      "20              word_freq_your  Feature  Continuous        None   \n",
      "21              word_freq_font  Feature  Continuous        None   \n",
      "22               word_freq_000  Feature  Continuous        None   \n",
      "23             word_freq_money  Feature  Continuous        None   \n",
      "24                word_freq_hp  Feature  Continuous        None   \n",
      "25               word_freq_hpl  Feature  Continuous        None   \n",
      "26            word_freq_george  Feature  Continuous        None   \n",
      "27               word_freq_650  Feature  Continuous        None   \n",
      "28               word_freq_lab  Feature  Continuous        None   \n",
      "29              word_freq_labs  Feature  Continuous        None   \n",
      "30            word_freq_telnet  Feature  Continuous        None   \n",
      "31               word_freq_857  Feature  Continuous        None   \n",
      "32              word_freq_data  Feature  Continuous        None   \n",
      "33               word_freq_415  Feature  Continuous        None   \n",
      "34                word_freq_85  Feature  Continuous        None   \n",
      "35        word_freq_technology  Feature  Continuous        None   \n",
      "36              word_freq_1999  Feature  Continuous        None   \n",
      "37             word_freq_parts  Feature  Continuous        None   \n",
      "38                word_freq_pm  Feature  Continuous        None   \n",
      "39            word_freq_direct  Feature  Continuous        None   \n",
      "40                word_freq_cs  Feature  Continuous        None   \n",
      "41           word_freq_meeting  Feature  Continuous        None   \n",
      "42          word_freq_original  Feature  Continuous        None   \n",
      "43           word_freq_project  Feature  Continuous        None   \n",
      "44                word_freq_re  Feature  Continuous        None   \n",
      "45               word_freq_edu  Feature  Continuous        None   \n",
      "46             word_freq_table  Feature  Continuous        None   \n",
      "47        word_freq_conference  Feature  Continuous        None   \n",
      "48                 char_freq_;  Feature  Continuous        None   \n",
      "49                 char_freq_(  Feature  Continuous        None   \n",
      "50                 char_freq_[  Feature  Continuous        None   \n",
      "51                 char_freq_!  Feature  Continuous        None   \n",
      "52                 char_freq_$  Feature  Continuous        None   \n",
      "53                 char_freq_#  Feature  Continuous        None   \n",
      "54  capital_run_length_average  Feature  Continuous        None   \n",
      "55  capital_run_length_longest  Feature  Continuous        None   \n",
      "56    capital_run_length_total  Feature  Continuous        None   \n",
      "57                       Class   Target      Binary        None   \n",
      "\n",
      "                 description units missing_values  \n",
      "0                       None  None             no  \n",
      "1                       None  None             no  \n",
      "2                       None  None             no  \n",
      "3                       None  None             no  \n",
      "4                       None  None             no  \n",
      "5                       None  None             no  \n",
      "6                       None  None             no  \n",
      "7                       None  None             no  \n",
      "8                       None  None             no  \n",
      "9                       None  None             no  \n",
      "10                      None  None             no  \n",
      "11                      None  None             no  \n",
      "12                      None  None             no  \n",
      "13                      None  None             no  \n",
      "14                      None  None             no  \n",
      "15                      None  None             no  \n",
      "16                      None  None             no  \n",
      "17                      None  None             no  \n",
      "18                      None  None             no  \n",
      "19                      None  None             no  \n",
      "20                      None  None             no  \n",
      "21                      None  None             no  \n",
      "22                      None  None             no  \n",
      "23                      None  None             no  \n",
      "24                      None  None             no  \n",
      "25                      None  None             no  \n",
      "26                      None  None             no  \n",
      "27                      None  None             no  \n",
      "28                      None  None             no  \n",
      "29                      None  None             no  \n",
      "30                      None  None             no  \n",
      "31                      None  None             no  \n",
      "32                      None  None             no  \n",
      "33                      None  None             no  \n",
      "34                      None  None             no  \n",
      "35                      None  None             no  \n",
      "36                      None  None             no  \n",
      "37                      None  None             no  \n",
      "38                      None  None             no  \n",
      "39                      None  None             no  \n",
      "40                      None  None             no  \n",
      "41                      None  None             no  \n",
      "42                      None  None             no  \n",
      "43                      None  None             no  \n",
      "44                      None  None             no  \n",
      "45                      None  None             no  \n",
      "46                      None  None             no  \n",
      "47                      None  None             no  \n",
      "48                      None  None             no  \n",
      "49                      None  None             no  \n",
      "50                      None  None             no  \n",
      "51                      None  None             no  \n",
      "52                      None  None             no  \n",
      "53                      None  None             no  \n",
      "54                      None  None             no  \n",
      "55                      None  None             no  \n",
      "56                      None  None             no  \n",
      "57  spam (1) or not spam (0)  None             no  \n"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = spambase.data.features\n",
    "y = spambase.data.targets\n",
    "\n",
    "# convert to numpy\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "  \n",
    "# metadata \n",
    "print(spambase.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(spambase.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data standardization and train-test split\n",
    "\n",
    "In this section, we standardize the dataset and split it into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = standardize(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_std, \n",
    "    y, \n",
    "    train_size=TRAIN_SIZE,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and tuning the model\n",
    "\n",
    "In this section, we create an instance of the `MIOTree` model using the defined parameters and then tune the model using the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART\tDepth: 2\tAlpha: 2\tAccuracy: 0.8782608695652174\tDuration: 0.001528024673461914\n",
      "MIO\tDepth: 2\tAlpha: 2\tAccuracy: 0.6260869565217392\tDuration: 2.005417823791504\n",
      "CART\tDepth: 2\tAlpha: 3\tAccuracy: 0.8782608695652174\tDuration: 0.0015611648559570312\n",
      "MIO\tDepth: 2\tAlpha: 3\tAccuracy: 0.6260869565217392\tDuration: 1.7708189487457275\n",
      "CART\tDepth: 2\tAlpha: 4\tAccuracy: 0.8782608695652174\tDuration: 0.0016911029815673828\n",
      "MIO\tDepth: 2\tAlpha: 4\tAccuracy: 0.6260869565217392\tDuration: 2.0718252658843994\n",
      "CART\tDepth: 2\tAlpha: 5\tAccuracy: 0.8782608695652174\tDuration: 0.0017359256744384766\n",
      "MIO\tDepth: 2\tAlpha: 5\tAccuracy: 0.6260869565217392\tDuration: 2.1114439964294434\n",
      "CART\tDepth: 2\tAlpha: 6\tAccuracy: 0.8782608695652174\tDuration: 0.0016360282897949219\n",
      "MIO\tDepth: 2\tAlpha: 6\tAccuracy: 0.6260869565217392\tDuration: 2.1748416423797607\n",
      "CART\tDepth: 2\tAlpha: 7\tAccuracy: 0.8782608695652174\tDuration: 0.0015730857849121094\n",
      "MIO\tDepth: 2\tAlpha: 7\tAccuracy: 0.6260869565217392\tDuration: 2.2070960998535156\n",
      "CART\tDepth: 3\tAlpha: 2\tAccuracy: 0.9173913043478261\tDuration: 0.001987934112548828\n",
      "MIO\tDepth: 3\tAlpha: 2\tAccuracy: 0.6260869565217392\tDuration: 5.298513174057007\n",
      "CART\tDepth: 3\tAlpha: 3\tAccuracy: 0.9173913043478261\tDuration: 0.0018906593322753906\n",
      "MIO\tDepth: 3\tAlpha: 3\tAccuracy: 0.6260869565217392\tDuration: 4.776582956314087\n",
      "CART\tDepth: 3\tAlpha: 4\tAccuracy: 0.9152173913043479\tDuration: 0.0019681453704833984\n",
      "MIO\tDepth: 3\tAlpha: 4\tAccuracy: 0.6260869565217392\tDuration: 5.068918943405151\n",
      "CART\tDepth: 3\tAlpha: 5\tAccuracy: 0.9173913043478261\tDuration: 0.0023648738861083984\n",
      "MIO\tDepth: 3\tAlpha: 5\tAccuracy: 0.6260869565217392\tDuration: 5.896799325942993\n",
      "CART\tDepth: 3\tAlpha: 6\tAccuracy: 0.9173913043478261\tDuration: 0.0019769668579101562\n",
      "MIO\tDepth: 3\tAlpha: 6\tAccuracy: 0.6260869565217392\tDuration: 4.706157207489014\n",
      "CART\tDepth: 3\tAlpha: 7\tAccuracy: 0.9173913043478261\tDuration: 0.0020639896392822266\n",
      "MIO\tDepth: 3\tAlpha: 7\tAccuracy: 0.6260869565217392\tDuration: 4.723724126815796\n",
      "Final model accuracy: 0.6260869565217392, alpha: 2, depth: 2\n",
      "Train Accuracy: 62.60869565217392%\n",
      "Confusion Matrix:\n",
      "Act/Pred\t(0)\t(1)\n",
      "(0)\t\t288\t0\t\n",
      "(1)\t\t172\t0\t\n",
      "Test Accuracy: 60.371890847621344%\n"
     ]
    }
   ],
   "source": [
    "model = MIOTree.MIOTree(\n",
    "    alpha=ALPHA, \n",
    "    min_samples_per_leaf=MIN_SAMPLES_PER_LEAF, \n",
    "    max_depth=MAX_DEPTH,\n",
    "    X_train=X_train, \n",
    "    y_train=y_train)\n",
    "\n",
    "tuned_model = model.tune(X_test, y_test)\n",
    "\n",
    "accuracy = tuned_model.calculate_accuracy()\n",
    "print(f'Train Accuracy: {accuracy * 100}%')\n",
    "\n",
    "confusion_matrix = tuned_model.calculate_confusion_matrix()\n",
    "print_confusion_matrix(np.unique(model.y_train), confusion_matrix)\n",
    "\n",
    "accuracy = tuned_model.calculate_accuracy(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing different solvers\n",
    "\n",
    "In this section, we compare the performance of different solvers on the `MIOTree` model by solving the model with each solver and evaluating its accuracy on both training and test datasets, the solvers compared are `gurobi`, `glpk`, and `ipopt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: gurobi\n",
      "\n",
      "Problem: \n",
      "- Name: x1\n",
      "  Lower bound: 0.5972222222222222\n",
      "  Upper bound: 0.5972222222222222\n",
      "  Number of objectives: 1\n",
      "  Number of constraints: 37464\n",
      "  Number of variables: 8357\n",
      "  Number of binary variables: 8278\n",
      "  Number of integer variables: 8342\n",
      "  Number of continuous variables: 15\n",
      "  Number of nonzeros: 1782432\n",
      "  Sense: minimize\n",
      "Solver: \n",
      "- Status: ok\n",
      "  Return code: 0\n",
      "  Message: Model was solved to optimality (subject to tolerances), and an optimal solution is available.\n",
      "  Termination condition: optimal\n",
      "  Termination message: Model was solved to optimality (subject to tolerances), and an optimal solution is available.\n",
      "  Wall time: 4.950109004974365\n",
      "  Error rc: 0\n",
      "  Time: 5.574570894241333\n",
      "Solution: \n",
      "- number of solutions: 0\n",
      "  number of solutions displayed: 0\n",
      "\n",
      "Root: (1) None\n",
      "    L--- (2) None\n",
      "        L--- (4) None\n",
      "            L--- (8) None\n",
      "                L--- (16) 0\n",
      "                R--- (17) None\n",
      "            R--- (9) None\n",
      "                L--- (18) None\n",
      "                R--- (19) None\n",
      "        R--- (5) None\n",
      "            L--- (10) None\n",
      "                L--- (20) None\n",
      "                R--- (21) None\n",
      "            R--- (11) None\n",
      "                L--- (22) None\n",
      "                R--- (23) None\n",
      "    R--- (3) None\n",
      "        L--- (6) None\n",
      "            L--- (12) None\n",
      "                L--- (24) None\n",
      "                R--- (25) None\n",
      "            R--- (13) None\n",
      "                L--- (26) None\n",
      "                R--- (27) None\n",
      "        R--- (7) None\n",
      "            L--- (14) None\n",
      "                L--- (28) None\n",
      "                R--- (29) None\n",
      "            R--- (15) None\n",
      "                L--- (30) None\n",
      "                R--- (31) None\n",
      "Solver: ipopt\n",
      "\n",
      "Problem: \n",
      "- Lower bound: -inf\n",
      "  Upper bound: inf\n",
      "  Number of objectives: 1\n",
      "  Number of constraints: 37464\n",
      "  Number of variables: 8357\n",
      "  Sense: unknown\n",
      "Solver: \n",
      "- Status: ok\n",
      "  Message: Ipopt 3.14.16\\x3a Optimal Solution Found\n",
      "  Termination condition: optimal\n",
      "  Id: 0\n",
      "  Error rc: 0\n",
      "  Time: 183.9375741481781\n",
      "Solution: \n",
      "- number of solutions: 0\n",
      "  number of solutions displayed: 0\n",
      "\n",
      "Root: (1) None\n",
      "    L--- (2) None\n",
      "        L--- (4) None\n",
      "            L--- (8) None\n",
      "                L--- (16) None\n",
      "                R--- (17) None\n",
      "            R--- (9) None\n",
      "                L--- (18) None\n",
      "                R--- (19) None\n",
      "        R--- (5) None\n",
      "            L--- (10) None\n",
      "                L--- (20) None\n",
      "                R--- (21) None\n",
      "            R--- (11) None\n",
      "                L--- (22) None\n",
      "                R--- (23) None\n",
      "    R--- (3) None\n",
      "        L--- (6) None\n",
      "            L--- (12) None\n",
      "                L--- (24) None\n",
      "                R--- (25) None\n",
      "            R--- (13) None\n",
      "                L--- (26) None\n",
      "                R--- (27) None\n",
      "        R--- (7) None\n",
      "            L--- (14) None\n",
      "                L--- (28) None\n",
      "                R--- (29) None\n",
      "            R--- (15) None\n",
      "                L--- (30) None\n",
      "                R--- (31) None\n"
     ]
    }
   ],
   "source": [
    "# Comparisons\n",
    "results = []\n",
    "max_easy_depth = 4\n",
    "for solver in ['gurobi', 'ipopt']:\n",
    "    model = MIOTree.MIOTree(\n",
    "        alpha=ALPHA, \n",
    "        min_samples_per_leaf=MIN_SAMPLES_PER_LEAF, \n",
    "        max_depth=max_easy_depth,\n",
    "        X_train=X_train, \n",
    "        y_train=y_train)\n",
    "\n",
    "    print(f\"Solver: {solver}\")\n",
    "    result = {\n",
    "        'model': model,\n",
    "    }\n",
    "    result['solver'] = model.solve(solver)\n",
    "    results.append(result)\n",
    "    print(result['solver'])\n",
    "    \n",
    "    \"\"\" accuracy = model.calculate_accuracy()\n",
    "    print(f'Train Accuracy: {accuracy * 100}%')\n",
    "    \n",
    "    confusion_matrix = model.calculate_confusion_matrix()\n",
    "    print_confusion_matrix(np.unique(model.y_train), confusion_matrix)\n",
    "\n",
    "    accuracy = model.calculate_accuracy(X_test, y_test)\n",
    "    print(f'Test Accuracy: {accuracy * 100}%') \"\"\"\n",
    "\n",
    "    leaf_predictions = extract_leaf_predictions(model)\n",
    "    model.tree.print_tree(leaf_predictions)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
